{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktik pertemuan 1: Pengenalan Big Data dan Overview Teknologi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tujuan\n",
    "Pada akhir praktikum ini, mahasiswa diharapkan mampu:\n",
    "1. Memahami konsep dasar Big Data.\n",
    "2. Menjelaskan karakteristik dan tantangan Big Data (Volume, Variety, Velocity, dan Veracity).\n",
    "3. Mengenal teknologi yang digunakan dalam ekosistem Big Data.\n",
    "4. Menginstal dan mengonfigurasi Anaconda untuk bekerja dengan alat Big Data seperti Hadoop dan Spark.\n",
    "5. Memulai praktik sederhana terkait pengolahan data menggunakan PySpark dan Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peralatan yang Dibutuhkan\n",
    "1. Anaconda (untuk manajemen lingkungan)\n",
    "2. Jupyter Notebook (bawaan dari Anaconda)\n",
    "3. PySpark (untuk pemrosesan data skala besar)\n",
    "4. Pandas (untuk data analysis)\n",
    "5. Python (bawaan dari Anaconda)\n",
    "6. matplotlib (Untuk visualisasi data)\n",
    "7. OpenJDK (untuk runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalasi Anaconda dan Membuat environment\n",
    "- **Langkah 1: Unduh dan Instal Anaconda**\n",
    "  Anaconda adalah platform distribusi Python yang menyertakan berbagai alat pengembangan, termasuk Jupyter Notebook. Ikuti langkah-langkah instalasi sesuai sistem operasi:\n",
    "  - Unduh Anaconda: [Download Anaconda](https://www.anaconda.com/products/individual)\n",
    "  - Instal sesuai instruksi yang ada di situs web tersebut (Windows/Mac/Linux).\n",
    "\n",
    "- **Langkah 2: Buat environment Python baru**\n",
    "  Pergi ke menu pada bagian kiri dan tekan environment\n",
    "\n",
    "  ![alt text](images/image-4.png)\n",
    "\n",
    "  kemudian klik tombol create dan tambahkan nama, pilih versi python dan klik tombol create\n",
    "\n",
    "  ![alt text](images/image-5.png)\n",
    "  \n",
    "- **Langkah 3: Menginstal PySpark di Environment Baru**\n",
    "  Setelah Anaconda terinstal, tambahkan PySpark dengan cara menekan tombol play dan buka melalui terminal \n",
    "\n",
    "  ![alt text](images/image-6.png)\n",
    "  \n",
    "  berikut adalah command nya:\n",
    "  ```bash\n",
    "  pip install pyspark==3.4.1\n",
    "  ```\n",
    "  ![alt text](images/image-7.png)\n",
    "\n",
    "- **Langkah 4: Menginstal Pandas**\n",
    "  Untuk memudahkan data analysis, install Pandas:\n",
    "  ```bash\n",
    "  pip install pandas\n",
    "  ```\n",
    "  ![alt text](images/image-8.png)\n",
    "\n",
    "- **Langkah 5: Menginstal Findspark**\n",
    "  ```bash\n",
    "  pip install findspark\n",
    "  ```\n",
    "  ![alt text](images/image-9.png)\n",
    "\n",
    "- **Langkah 6: Menginstal Matplotlib**\n",
    "  ```bash\n",
    "  pip install matplotlib\n",
    "  ```\n",
    "  ![alt text](images/image-10.png)\n",
    "\n",
    "- **Langkah 7: Menginstal OpenJDK**\n",
    "  anda dapat pergi ke menu environment pada anaconda dan memasang OpenJDK dari kolom pencarian.\n",
    "\n",
    "  ![alt text](images/image-1.png)\n",
    "  \n",
    "  anda dapat apply setelah memilih package nya\n",
    "\n",
    "  ![alt text](images/image-2.png)\n",
    "\n",
    "- **Langkah 8: Mengubah environment pada IDE pilihan**\n",
    "  anda dapat menekan menu kernel pada kanan atas, dan ubah menjadi python environment > env yang sudah dibuat\n",
    "\n",
    "  ![alt text](images/image-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pengenalan dan Praktik Dasar PySpark dan Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Tugas 1**: Jalankan kode di bawah dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34, \"Petinju\", \"Menonton TV\", \"Laki-Laki\"), \n",
    "        (\"Budi\", 23, \"Peternak Pokemon\", \"Berduel\", \"Laki-Laki\"),\n",
    "        (\"Citra\", 29, \"Streamer\", \"Makan\", \"Perempuan\"), \n",
    "        (\"Dina\", 45, \"Koki\", \"Berburu Ubur-Ubur\", \"Perempuan\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Penjelasan Kode</h5>\n",
    "\n",
    "- ``` bash from pyspark.sql import SparkSession ```\n",
    "    - Mengimpor modul SparkSession dari library pyspark.sql.\n",
    "- ``` bash spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate() ```\n",
    "    - Memulai sesi Spark dengan nama aplikasi “BigDataPractice”. Jika sesi Spark sudah ada, maka akan menggunakan sesi yang sudah ada tersebut.\n",
    "- ``` bash data = [(\"Ali\", ...] ```\n",
    "    - Membuat daftar data yang berisi beberapa tuple. Setiap tuple mewakili satu baris data dengan informasi nama, usia, pekerjaan, hobi, dan gender.\n",
    "- ``` bash columns = [\"Nama\", ...] ```\n",
    "    - Mendefinisikan daftar nama kolom untuk DataFrame.\n",
    "- ``` bash df = spark.createDataFrame(data, columns)```\n",
    "    - Membuat DataFrame Spark dari data yang telah didefinisikan sebelumnya dengan nama kolom yang sesuai.\n",
    "- ``` bash df.show()```\n",
    "    - Menampilkan isi DataFrame ke konsol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Praktik PySpark Lanjutan\n",
    "- **Tugas 2**: Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "print(\"DataFrame:\")\n",
    "df.show()\n",
    "\n",
    "# Filtering data\n",
    "df_filtered = df.filter(df['Usia'] > 30)\n",
    "print(\"Filtered (Usia > 30):\")\n",
    "df_filtered.show()\n",
    "\n",
    "# Menghitung rata-rata usia\n",
    "df_avg = df.groupBy().agg(avg(\"Usia\"))\n",
    "print(\"Rata-Rata Usia:\")\n",
    "df_avg.show()\n",
    "\n",
    "# Mengurutkan data berdasarkan usia\n",
    "df_sorted = df.orderBy(\"Usia\", ascending=False)\n",
    "print(\"Sorted by Usia (descending):\")\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Penjelasan Kode</h5>\n",
    "\n",
    "- ``` bash from pyspark.sql import SparkSession ```\n",
    "    - Mengimpor modul SparkSession dari library pyspark.sql.\n",
    "- ``` bash from pyspark.sql.functions import avg ```\n",
    "    - Mengimpor fungsi avg dari library pyspark.sql.functions untuk menghitung rata-rata.\n",
    "- ``` bash spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate() ```\n",
    "    - Memulai sesi Spark dengan nama aplikasi “BigDataPractice”. Jika sesi Spark sudah ada, maka akan menggunakan sesi yang sudah ada tersebut.\n",
    "- ``` bash data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)] ```\n",
    "    - Membuat daftar data yang berisi beberapa tuple. Setiap tuple mewakili satu baris data dengan informasi nama dan usia.\n",
    "- ``` bash columns = [\"Nama\", \"Usia\"] ```\n",
    "    - Mendefinisikan daftar nama kolom untuk DataFrame.\n",
    "- ``` bash df = spark.createDataFrame(data, columns) ```\n",
    "    - Membuat DataFrame Spark dari data yang telah didefinisikan sebelumnya dengan nama kolom yang sesuai.\n",
    "- ``` bash print(\"DataFrame:\") ```\n",
    "    - Mencetak teks \"DataFrame:\" ke konsol.\n",
    "- ``` bash df.show() ```\n",
    "    - Menampilkan isi DataFrame ke konsol.\n",
    "- ``` bash df_filtered = df.filter(df['Usia'] > 30) ```\n",
    "    - Memfilter DataFrame untuk hanya menyertakan baris di mana usia lebih dari 30.\n",
    "- ``` bash print(\"Filtered (Usia > 30):\") ```\n",
    "    - Mencetak teks \"Filtered (Usia > 30):\" ke konsol.\n",
    "- ``` bash df_filtered.show() ```\n",
    "    - Menampilkan isi DataFrame yang telah difilter ke konsol.\n",
    "- ``` bash df_avg = df.groupBy().agg(avg(\"Usia\")) ```\n",
    "    - Mengelompokkan data (dalam hal ini, tidak ada pengelompokan spesifik) dan menghitung rata-rata usia.\n",
    "- ``` bash print(\"Rata-Rata Usia:\") ```\n",
    "    - Mencetak teks \"Rata-Rata Usia:\" ke konsol.\n",
    "- ``` bash df_avg.show() ```\n",
    "    - Menampilkan hasil rata-rata usia ke konsol.\n",
    "- ``` bash df_sorted = df.orderBy(\"Usia\", ascending=False) ```\n",
    "    - Mengurutkan DataFrame berdasarkan usia dalam urutan menurun.\n",
    "- ``` bash print(\"Sorted by Usia (descending):\") ```\n",
    "    - Mencetak teks \"Sorted by Usia (descending):\" ke konsol.\n",
    "- ``` bash df_sorted.show() ```\n",
    "    - Menampilkan DataFrame yang telah diurutkan ke konsol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Praktik dengan Pandas\n",
    "- **Tugas 3**: Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menambahkan kolom baru\n",
    "gender = [\"Laki-laki\", \"Laki-laki\", \"Perempuan\", \"Perempuan\"]\n",
    "df_pandas['Gender'] = gender\n",
    "\n",
    "print(\"DataFrame:\")\n",
    "print(df_pandas)\n",
    "\n",
    "# Filtering usia\n",
    "filtered_df = df_pandas[df_pandas['Usia'] > 30]\n",
    "\n",
    "print(\"\\nUsia > 30:\")\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Penjelasan Kode</h5>\n",
    "\n",
    "- ``` bash import pandas as pd ```\n",
    "    - Mengimpor pustaka pandas dan memberi alias pd.\n",
    "- ``` bash data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]} ```\n",
    "    - Membuat kamus data dengan dua kunci: \"Nama\" dan \"Usia\". Setiap kunci memiliki daftar nilai yang sesuai.\n",
    "- ``` bash df_pandas = pd.DataFrame(data_pandas) ```\n",
    "    - Membuat DataFrame pandas dari kamus data yang telah didefinisikan sebelumnya.\n",
    "- ``` bash gender = [\"Laki-laki\", \"Laki-laki\", \"Perempuan\", \"Perempuan\"] ```\n",
    "    - Membuat daftar gender yang berisi jenis kelamin untuk setiap individu.\n",
    "- ``` bash df_pandas['Gender'] = gender ```\n",
    "    - Menambahkan kolom baru ke DataFrame df_pandas dengan nama \"Gender\" dan mengisinya dengan daftar gender.\n",
    "- ``` bash print(\"DataFrame:\") ```\n",
    "    - Mencetak teks \"DataFrame:\" ke konsol.\n",
    "- ``` bash print(df_pandas) ```\n",
    "    - Menampilkan isi DataFrame df_pandas ke konsol.\n",
    "- ``` bash filtered_df = df_pandas[df_pandas['Usia'] > 30] ```\n",
    "    - Memfilter DataFrame df_pandas untuk hanya menyertakan baris di mana usia lebih dari 30.\n",
    "- ``` bash print(\"\\nUsia > 30:\") ```\n",
    "    - Mencetak teks \"Usia > 30:\" ke konsol.\n",
    "- ``` bash print(filtered_df) ```\n",
    "    - Menampilkan isi DataFrame yang telah difilter ke konsol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Praktik Pandas Lanjutan\n",
    "- **Tugas 4**: Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import catppuccin\n",
    "\n",
    "# Mengubah tema matplotlib\n",
    "plt.style.use(catppuccin.PALETTE.mocha.identifier)\n",
    "\n",
    "# DataFrame Pandas pertama\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# DataFrame Pandas kedua\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Menggabungkan dua DataFrame dengan Nama\n",
    "df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\")\n",
    "print(\"DataFrame Gabungan:\")\n",
    "print(df_joined)\n",
    "\n",
    "# statistik deskriptif\n",
    "print(\"\\nStatistik Deskriptif:\")\n",
    "print(df_pandas.describe())\n",
    "\n",
    "# Visualisasi Data Usia\n",
    "df_pandas['Usia'].plot(kind='bar')\n",
    "plt.xlabel('Nama')\n",
    "plt.ylabel('Usia')\n",
    "plt.title('Usia per Nama')\n",
    "plt.xticks(ticks=range(len(df_pandas['Nama'])), labels=df_pandas['Nama'], rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Penjelasan Kode</h5>\n",
    "\n",
    "- ``` bash import pandas as pd ```\n",
    "    - Mengimpor pustaka pandas dan memberi alias pd.\n",
    "- ``` bash import matplotlib.pyplot as plt ```\n",
    "    - Mengimpor pustaka matplotlib.pyplot dan memberi alias plt untuk visualisasi data.\n",
    "- ``` bash import catppuccin ```\n",
    "    - Mengimpor pustaka catppuccin untuk mengubah tema matplotlib.\n",
    "- ``` bash plt.style.use(catppuccin.PALETTE.mocha.identifier) ```\n",
    "    - Mengubah tema matplotlib menggunakan tema dari pustaka catppuccin.\n",
    "- ``` bash data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]} ```\n",
    "    - Membuat kamus data pertama dengan dua kunci: \"Nama\" dan \"Usia\". Setiap kunci memiliki daftar nilai yang sesuai.\n",
    "- ``` bash df_pandas = pd.DataFrame(data_pandas) ```\n",
    "    - Membuat DataFrame pandas dari kamus data pertama yang telah didefinisikan sebelumnya.\n",
    "- ``` bash data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]} ```\n",
    "    - Membuat kamus data kedua dengan dua kunci: \"Nama\" dan \"Pekerjaan\". Setiap kunci memiliki daftar nilai yang sesuai.\n",
    "- ``` bash df_pandas_2 = pd.DataFrame(data_pandas_2) ```\n",
    "    - Membuat DataFrame pandas dari kamus data kedua yang telah didefinisikan sebelumnya.\n",
    "- ``` bash df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\") ```\n",
    "    - Menggabungkan dua DataFrame berdasarkan kolom \"Nama\".\n",
    "- ``` bash print(\"DataFrame Gabungan:\") ```\n",
    "    - Mencetak teks \"DataFrame Gabungan:\" ke konsol.\n",
    "- ``` bash print(df_joined) ```\n",
    "    - Menampilkan isi DataFrame gabungan ke konsol.\n",
    "- ``` bash print(\"\\nStatistik Deskriptif:\") ```\n",
    "    - Mencetak teks \"Statistik Deskriptif:\" ke konsol.\n",
    "- ``` bash print(df_pandas.describe()) ```\n",
    "    - Menampilkan statistik deskriptif dari DataFrame pertama ke konsol.\n",
    "- ``` bash df_pandas['Usia'].plot(kind='bar') ```\n",
    "    - Membuat plot batang dari kolom \"Usia\" pada DataFrame pertama.\n",
    "- ``` bash plt.xlabel('Nama') ```\n",
    "    - Menambahkan label \"Nama\" pada sumbu x.\n",
    "- ``` bash plt.ylabel('Usia') ```\n",
    "    - Menambahkan label \"Usia\" pada sumbu y.\n",
    "- ``` bash plt.title('Usia per Nama') ```\n",
    "    - Menambahkan judul \"Usia per Nama\" pada plot.\n",
    "- ``` bash plt.xticks(ticks=range(len(df_pandas['Nama'])), labels=df_pandas['Nama'], rotation=0) ```\n",
    "    - Menyesuaikan label pada sumbu x dengan nama-nama dari DataFrame pertama dan mengatur rotasi label menjadi 0 derajat.\n",
    "- ``` bash plt.show() ```\n",
    "    - Menampilkan plot ke layar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Menggabungkan PySpark dan Pandas\n",
    "- **Tugas 5**: Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "print(\"DataFrame Pandas dari PySpark:\")\n",
    "print(df_pandas_from_spark)\n",
    "\n",
    "print(\"\\nDataFrame PySpark dari Pandas:\")\n",
    "df_spark_from_pandas.show()\n",
    "\n",
    "# Menggabungkan kedua DataFrame Pandas\n",
    "df_combined_pandas = pd.concat([df_pandas_from_spark, df_pandas])\n",
    "\n",
    "# Mengonversi DataFrame gabungan kembali ke PySpark\n",
    "df_combined_spark = spark.createDataFrame(df_combined_pandas)\n",
    "\n",
    "# Menghitung rata-rata kolom 'Usia' di DataFrame gabungan PySpark\n",
    "avg_usia_combined = df_combined_spark.agg({'Usia': 'avg'}).collect()[0][0]\n",
    "print(\"\\nRata-rata Usia di DataFrame gabungan:\")\n",
    "print(avg_usia_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Penjelasan Kode</h5>\n",
    "\n",
    "- ``` bash df_pandas_from_spark = df.toPandas() ```\n",
    "    - Mengonversi DataFrame dari PySpark ke Pandas.\n",
    "- ``` bash df_spark_from_pandas = spark.createDataFrame(df_pandas) ```\n",
    "    - Mengonversi DataFrame dari Pandas ke PySpark.\n",
    "- ``` bash print(\"DataFrame Pandas dari PySpark:\") ```\n",
    "    - Mencetak teks \"DataFrame Pandas dari PySpark:\" ke konsol.\n",
    "- ``` bash print(df_pandas_from_spark) ```\n",
    "    - Menampilkan DataFrame hasil konversi dari PySpark ke Pandas ke konsol.\n",
    "- ``` bash print(\"\\nDataFrame PySpark dari Pandas:\") ```\n",
    "    - Mencetak teks \"DataFrame PySpark dari Pandas:\" ke konsol.\n",
    "- ``` bash df_spark_from_pandas.show() ```\n",
    "    - Menampilkan DataFrame hasil konversi dari Pandas ke PySpark ke konsol.\n",
    "- ``` bash df_combined_pandas = pd.concat([df_pandas_from_spark, df_pandas]) ```\n",
    "    - Menggabungkan kedua DataFrame Pandas.\n",
    "- ``` bash df_combined_spark = spark.createDataFrame(df_combined_pandas) ```\n",
    "    - Mengonversi DataFrame gabungan kembali ke PySpark.\n",
    "- ``` bash avg_usia_combined = df_combined_spark.agg({'Usia': 'avg'}).collect()[0][0] ```\n",
    "    - Menghitung rata-rata kolom 'Usia' di DataFrame gabungan PySpark.\n",
    "- ``` bash print(\"\\nRata-rata Usia di DataFrame gabungan:\") ```\n",
    "    - Mencetak teks \"Rata-rata Usia di DataFrame gabungan:\" ke konsol.\n",
    "- ``` bash print(avg_usia_combined) ```\n",
    "    - Menampilkan hasil rata-rata usia di DataFrame gabungan ke konsol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Konversi Data antara PySpark dan Pandas\n",
    "- **Tugas 6**: Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengkonversi DataFrame PySpark ke Pandas\n",
    "df_spark_pandas = df_spark_from_pandas.toPandas()\n",
    "\n",
    "# Menggabungkan kedua DataFrame Pandas\n",
    "df_combined = pd.concat([df_pandas_from_spark, df_spark_pandas], ignore_index=True)\n",
    "\n",
    "# Menghitung nilai maksimum usia\n",
    "max_age = df_combined['Usia'].max()\n",
    "print(\"Nilai maksimum usia:\", max_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Penjelasan Kode</h5>\n",
    "\n",
    "- ``` bash df_spark_pandas = df_spark_from_pandas.toPandas() ```\n",
    "    - Mengonversi DataFrame PySpark ke Pandas.\n",
    "- ``` bash df_combined = pd.concat([df_pandas_from_spark, df_spark_pandas], ignore_index=True) ```\n",
    "    - Menggabungkan kedua DataFrame Pandas dan mengabaikan indeks asli.\n",
    "- ``` bash max_age = df_combined['Usia'].max() ```\n",
    "    - Menghitung nilai maksimum dari kolom 'Usia' di DataFrame gabungan.\n",
    "- ``` bash print(\"Nilai maksimum usia:\", max_age) ```\n",
    "    - Mencetak teks \"Nilai maksimum usia:\" dan nilai maksimum usia ke konsol."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
